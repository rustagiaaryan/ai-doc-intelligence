# FILE: services/ingestion-worker/.env.example

# Service Configuration
SERVICE_NAME=ingestion-worker
PORT=8003
ENV=development

# Database
DATABASE_URL=postgresql://docai:docai_local_password@postgres:5432/docai

# Redis (for task queue)
REDIS_URL=redis://redis:6379/2

# S3/MinIO Configuration
S3_ENDPOINT_URL=http://minio:9000
S3_ACCESS_KEY_ID=minioadmin
S3_SECRET_ACCESS_KEY=minioadmin
S3_BUCKET_NAME=documents
S3_REGION=us-east-1
USE_SSL=false

# LLM Proxy Service
LLM_PROXY_URL=http://llm-proxy:8002

# Text Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_CHUNKS_PER_DOCUMENT=500

# CORS (JSON array format)
CORS_ORIGINS=["http://localhost:3000","http://localhost:8080"]
